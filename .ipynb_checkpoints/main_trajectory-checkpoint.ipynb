{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch recurrent neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demosntrates the three most common types of recurrent neural networks. \n",
    "Namely, we focus on: \n",
    "    Simple recurrent neural network   (RNN) \n",
    "    Gated recurrent units             (GRU)\n",
    "    Long short term memory netowrk    (LSTM) \n",
    "\n",
    "The models are nicely demonstrated and explained in the following post:  \n",
    "http://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "\n",
    "The models are trained on a one dimensional time series of a noisy sin-wave. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages and dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "%matplotlib inline\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available:  True\n"
     ]
    }
   ],
   "source": [
    "use_gpu=torch.cuda.is_available()\n",
    "print(\"GPU is available: \",  use_gpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "look_back=5        # historic time window\n",
    "look_forward=1        # prediction time horizont\n",
    "hidden_size= 4       # dimension of hidden variable h\n",
    "num_layer= 2          # number of LSTM layers\n",
    "dropout=   0.3      # dropout rate after each LSTM layer\n",
    "\n",
    "epochs=100\n",
    "\n",
    "sample_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate data \n",
    "average_steps=30\n",
    "std=10\n",
    "R={}\n",
    "def generate_trajectories(sample= sample_size, average_steps=average_steps, std=std):\n",
    "    for num in np.arange(sample):\n",
    "        start=np.array(np.random.choice([0, 1], 2))\n",
    "        if (start==np.array([1,1])).all():\n",
    "            start=np.array([ 1, np.random.rand()])\n",
    "            end= np.array([ 0, np.random.rand()])\n",
    "        elif (start==np.array([0,0])).all():\n",
    "            start=np.array([np.random.rand(), 1])\n",
    "            end= np.array([ np.random.rand(), 0])\n",
    "        else: \n",
    "            start=start*np.random.rand(2)\n",
    "            end= start*np.random.rand(2)+(start==0)*1.\n",
    "        a=np.vstack((start, end))\n",
    "        v=end-start\n",
    "        \n",
    "        n=np.clip(int(np.random.normal(average_steps, std)), 1, 10000)\n",
    "        v= v/n\n",
    "        x=np.linspace(start[0], end[0], n, endpoint=True)\n",
    "        y=np.linspace(start[1], end[1], n, endpoint=True)\n",
    "        r=np.vstack((x,y))\n",
    "        R[num]=r\n",
    "    return R \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset=generate_trajectories()\n",
    "for index, trajectory in dataset.items():\n",
    "    plt.plot(trajectory[0], trajectory[1],  label=\"train\") \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back, look_forward):\n",
    "    dataX, dataY = {}, {}\n",
    "    for index, item in dataset.items():\n",
    "        dataX[index]=[]\n",
    "        dataY[index]=[]\n",
    "        for i in range(np.shape(item)[1] - look_back- look_forward):\n",
    "            a = item[:, i:(i + look_back)]\n",
    "            dataX[index].append(a)\n",
    "            dataY[index].append(item[:,i + look_back:(i + look_back+look_forward)])\n",
    "    return dataX, dataY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_X, data_Y = create_dataset(dataset, look_back, look_forward)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x={} \n",
    "test_x={}\n",
    "train_y={} \n",
    "test_y={} \n",
    "\n",
    "\n",
    "split=0.7\n",
    "# Slit data to train and test data\n",
    "for index, item in data_X.items():\n",
    "    if index< split*len(data_X):\n",
    "        train_X = item\n",
    "     \n",
    "        train_X = np.array(train_X).reshape(2, -1, look_back)\n",
    "     \n",
    "        train_x[index] = torch.from_numpy(train_X).cuda()\n",
    "    else:\n",
    "        test_X = item\n",
    "        test_X = np.array(test_X).reshape(2, -1, look_back)\n",
    "        test_x[index] = torch.from_numpy(test_X).cuda()\n",
    "\n",
    "for index, item in data_Y.items():\n",
    "    if index< split*len(data_X):\n",
    "        train_Y = item\n",
    "        train_Y = np.array(train_Y).reshape(2, -1,  look_forward)\n",
    "        train_y[index] = torch.from_numpy(train_Y).cuda()\n",
    "    else:\n",
    "        test_Y = item\n",
    "        test_Y = np.array(test_Y).reshape(2, -1,  look_forward)\n",
    "        test_y[index] = torch.from_numpy(test_Y).cuda()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural netowrk \n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self, module, input_size, hidden_size, output_size, num_layers=num_layer, dropout=dropout):\n",
    "        if module==\"LSTM\":\n",
    "            super(model, self).__init__()    \n",
    "            self.rnn = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout) # rnn\n",
    "            self.reg = nn.Linear(hidden_size, output_size) \n",
    "\n",
    "        elif module==\"RNN\":\n",
    "            super(model, self).__init__()    \n",
    "            self.rnn = nn.RNN(input_size, hidden_size, num_layers, dropout=dropout) # rnn\n",
    "            self.reg = nn.Linear(hidden_size, output_size) \n",
    "        elif module==\"GRU\":\n",
    "            super(model, self).__init__()    \n",
    "            self.rnn = nn.GRU(input_size, hidden_size, num_layers, dropout=dropout) # rnn\n",
    "            self.reg = nn.Linear(hidden_size, output_size) \n",
    "        else:\n",
    "            print(\"No valid model\")\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x) # (seq, batch, hidden)\n",
    "        s, b, h = x.shape\n",
    "        x = x.view(s*b, h)\n",
    "        x = self.reg(x)\n",
    "        x = x.view(s, b, -1)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, inp, input_size, future=0):\n",
    "        outputs=[]\n",
    "        for i in range(future):# if we should predict the future\n",
    "            x, _ = self.rnn(inp) # (seq, batch, hidden)\n",
    "            s, b, h = x.shape\n",
    "            x = x.view(s*b, h)\n",
    "            x = self.reg(x)\n",
    "            x = x.view(s, b, -1)\n",
    "            outputs += [x]\n",
    "            inp[:,:,:(input_size-1)]=inp[:,:,1:]\n",
    "            inp[:,:,-1]=x[-1].item()\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LSTM': model(\n",
      "  (rnn): LSTM(5, 4, num_layers=2, dropout=0.3)\n",
      "  (reg): Linear(in_features=4, out_features=1, bias=True)\n",
      "), 'RNN': model(\n",
      "  (rnn): RNN(5, 4, num_layers=2, dropout=0.3)\n",
      "  (reg): Linear(in_features=4, out_features=1, bias=True)\n",
      "), 'GRU': model(\n",
      "  (rnn): GRU(5, 4, num_layers=2, dropout=0.3)\n",
      "  (reg): Linear(in_features=4, out_features=1, bias=True)\n",
      ")}\n"
     ]
    }
   ],
   "source": [
    "# initialize neural nets\n",
    "net={}\n",
    "models=['LSTM', 'RNN', 'GRU']\n",
    "optimizer={}\n",
    "for name in models:\n",
    "    net[name]=model(name, look_back, hidden_size, look_forward).cuda()\n",
    "    optimizer[name] = torch.optim.Adam(net[name].parameters(), lr=1e-2)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: tensor([[[ 0.1440,  0.1371,  0.1301,  0.1231,  0.1161],\n",
      "         [ 0.0000,  0.0500,  0.1000,  0.1500,  0.2000],\n",
      "         [ 0.1371,  0.1301,  0.1231,  0.1161,  0.1091],\n",
      "         [ 0.0500,  0.1000,  0.1500,  0.2000,  0.2500],\n",
      "         [ 0.1301,  0.1231,  0.1161,  0.1091,  0.1021],\n",
      "         [ 0.1000,  0.1500,  0.2000,  0.2500,  0.3000],\n",
      "         [ 0.1231,  0.1161,  0.1091,  0.1021,  0.0951],\n",
      "         [ 0.1500,  0.2000,  0.2500,  0.3000,  0.3500],\n",
      "         [ 0.1161,  0.1091,  0.1021,  0.0951,  0.0882],\n",
      "         [ 0.2000,  0.2500,  0.3000,  0.3500,  0.4000],\n",
      "         [ 0.1091,  0.1021,  0.0951,  0.0882,  0.0812],\n",
      "         [ 0.2500,  0.3000,  0.3500,  0.4000,  0.4500],\n",
      "         [ 0.1021,  0.0951,  0.0882,  0.0812,  0.0742],\n",
      "         [ 0.3000,  0.3500,  0.4000,  0.4500,  0.5000],\n",
      "         [ 0.0951,  0.0882,  0.0812,  0.0742,  0.0672]],\n",
      "\n",
      "        [[ 0.3500,  0.4000,  0.4500,  0.5000,  0.5500],\n",
      "         [ 0.0882,  0.0812,  0.0742,  0.0672,  0.0602],\n",
      "         [ 0.4000,  0.4500,  0.5000,  0.5500,  0.6000],\n",
      "         [ 0.0812,  0.0742,  0.0672,  0.0602,  0.0532],\n",
      "         [ 0.4500,  0.5000,  0.5500,  0.6000,  0.6500],\n",
      "         [ 0.0742,  0.0672,  0.0602,  0.0532,  0.0463],\n",
      "         [ 0.5000,  0.5500,  0.6000,  0.6500,  0.7000],\n",
      "         [ 0.0672,  0.0602,  0.0532,  0.0463,  0.0393],\n",
      "         [ 0.5500,  0.6000,  0.6500,  0.7000,  0.7500],\n",
      "         [ 0.0602,  0.0532,  0.0463,  0.0393,  0.0323],\n",
      "         [ 0.6000,  0.6500,  0.7000,  0.7500,  0.8000],\n",
      "         [ 0.0532,  0.0463,  0.0393,  0.0323,  0.0253],\n",
      "         [ 0.6500,  0.7000,  0.7500,  0.8000,  0.8500],\n",
      "         [ 0.0463,  0.0393,  0.0323,  0.0253,  0.0183],\n",
      "         [ 0.7000,  0.7500,  0.8000,  0.8500,  0.9000]]], dtype=torch.float64, device='cuda:0'), 1: tensor([[[ 0.4167,  0.4248,  0.4328,  0.4408,  0.4488],\n",
      "         [ 1.0000,  0.9744,  0.9487,  0.9231,  0.8974],\n",
      "         [ 0.4248,  0.4328,  0.4408,  0.4488,  0.4568],\n",
      "         [ 0.9744,  0.9487,  0.9231,  0.8974,  0.8718],\n",
      "         [ 0.4328,  0.4408,  0.4488,  0.4568,  0.4648],\n",
      "         [ 0.9487,  0.9231,  0.8974,  0.8718,  0.8462],\n",
      "         [ 0.4408,  0.4488,  0.4568,  0.4648,  0.4729],\n",
      "         [ 0.9231,  0.8974,  0.8718,  0.8462,  0.8205],\n",
      "         [ 0.4488,  0.4568,  0.4648,  0.4729,  0.4809],\n",
      "         [ 0.8974,  0.8718,  0.8462,  0.8205,  0.7949],\n",
      "         [ 0.4568,  0.4648,  0.4729,  0.4809,  0.4889],\n",
      "         [ 0.8718,  0.8462,  0.8205,  0.7949,  0.7692],\n",
      "         [ 0.4648,  0.4729,  0.4809,  0.4889,  0.4969],\n",
      "         [ 0.8462,  0.8205,  0.7949,  0.7692,  0.7436],\n",
      "         [ 0.4729,  0.4809,  0.4889,  0.4969,  0.5049],\n",
      "         [ 0.8205,  0.7949,  0.7692,  0.7436,  0.7179],\n",
      "         [ 0.4809,  0.4889,  0.4969,  0.5049,  0.5130],\n",
      "         [ 0.7949,  0.7692,  0.7436,  0.7179,  0.6923],\n",
      "         [ 0.4889,  0.4969,  0.5049,  0.5130,  0.5210],\n",
      "         [ 0.7692,  0.7436,  0.7179,  0.6923,  0.6667],\n",
      "         [ 0.4969,  0.5049,  0.5130,  0.5210,  0.5290],\n",
      "         [ 0.7436,  0.7179,  0.6923,  0.6667,  0.6410],\n",
      "         [ 0.5049,  0.5130,  0.5210,  0.5290,  0.5370],\n",
      "         [ 0.7179,  0.6923,  0.6667,  0.6410,  0.6154],\n",
      "         [ 0.5130,  0.5210,  0.5290,  0.5370,  0.5450],\n",
      "         [ 0.6923,  0.6667,  0.6410,  0.6154,  0.5897],\n",
      "         [ 0.5210,  0.5290,  0.5370,  0.5450,  0.5530],\n",
      "         [ 0.6667,  0.6410,  0.6154,  0.5897,  0.5641],\n",
      "         [ 0.5290,  0.5370,  0.5450,  0.5530,  0.5611],\n",
      "         [ 0.6410,  0.6154,  0.5897,  0.5641,  0.5385],\n",
      "         [ 0.5370,  0.5450,  0.5530,  0.5611,  0.5691],\n",
      "         [ 0.6154,  0.5897,  0.5641,  0.5385,  0.5128],\n",
      "         [ 0.5450,  0.5530,  0.5611,  0.5691,  0.5771],\n",
      "         [ 0.5897,  0.5641,  0.5385,  0.5128,  0.4872]],\n",
      "\n",
      "        [[ 0.5530,  0.5611,  0.5691,  0.5771,  0.5851],\n",
      "         [ 0.5641,  0.5385,  0.5128,  0.4872,  0.4615],\n",
      "         [ 0.5611,  0.5691,  0.5771,  0.5851,  0.5931],\n",
      "         [ 0.5385,  0.5128,  0.4872,  0.4615,  0.4359],\n",
      "         [ 0.5691,  0.5771,  0.5851,  0.5931,  0.6012],\n",
      "         [ 0.5128,  0.4872,  0.4615,  0.4359,  0.4103],\n",
      "         [ 0.5771,  0.5851,  0.5931,  0.6012,  0.6092],\n",
      "         [ 0.4872,  0.4615,  0.4359,  0.4103,  0.3846],\n",
      "         [ 0.5851,  0.5931,  0.6012,  0.6092,  0.6172],\n",
      "         [ 0.4615,  0.4359,  0.4103,  0.3846,  0.3590],\n",
      "         [ 0.5931,  0.6012,  0.6092,  0.6172,  0.6252],\n",
      "         [ 0.4359,  0.4103,  0.3846,  0.3590,  0.3333],\n",
      "         [ 0.6012,  0.6092,  0.6172,  0.6252,  0.6332],\n",
      "         [ 0.4103,  0.3846,  0.3590,  0.3333,  0.3077],\n",
      "         [ 0.6092,  0.6172,  0.6252,  0.6332,  0.6412],\n",
      "         [ 0.3846,  0.3590,  0.3333,  0.3077,  0.2821],\n",
      "         [ 0.6172,  0.6252,  0.6332,  0.6412,  0.6493],\n",
      "         [ 0.3590,  0.3333,  0.3077,  0.2821,  0.2564],\n",
      "         [ 0.6252,  0.6332,  0.6412,  0.6493,  0.6573],\n",
      "         [ 0.3333,  0.3077,  0.2821,  0.2564,  0.2308],\n",
      "         [ 0.6332,  0.6412,  0.6493,  0.6573,  0.6653],\n",
      "         [ 0.3077,  0.2821,  0.2564,  0.2308,  0.2051],\n",
      "         [ 0.6412,  0.6493,  0.6573,  0.6653,  0.6733],\n",
      "         [ 0.2821,  0.2564,  0.2308,  0.2051,  0.1795],\n",
      "         [ 0.6493,  0.6573,  0.6653,  0.6733,  0.6813],\n",
      "         [ 0.2564,  0.2308,  0.2051,  0.1795,  0.1538],\n",
      "         [ 0.6573,  0.6653,  0.6733,  0.6813,  0.6893],\n",
      "         [ 0.2308,  0.2051,  0.1795,  0.1538,  0.1282],\n",
      "         [ 0.6653,  0.6733,  0.6813,  0.6893,  0.6974],\n",
      "         [ 0.2051,  0.1795,  0.1538,  0.1282,  0.1026],\n",
      "         [ 0.6733,  0.6813,  0.6893,  0.6974,  0.7054],\n",
      "         [ 0.1795,  0.1538,  0.1282,  0.1026,  0.0769],\n",
      "         [ 0.6813,  0.6893,  0.6974,  0.7054,  0.7134],\n",
      "         [ 0.1538,  0.1282,  0.1026,  0.0769,  0.0513]]], dtype=torch.float64, device='cuda:0')}\n",
      "tensor([[[ 0.1440,  0.1371,  0.1301,  0.1231,  0.1161],\n",
      "         [ 0.0000,  0.0500,  0.1000,  0.1500,  0.2000],\n",
      "         [ 0.1371,  0.1301,  0.1231,  0.1161,  0.1091],\n",
      "         [ 0.0500,  0.1000,  0.1500,  0.2000,  0.2500],\n",
      "         [ 0.1301,  0.1231,  0.1161,  0.1091,  0.1021],\n",
      "         [ 0.1000,  0.1500,  0.2000,  0.2500,  0.3000],\n",
      "         [ 0.1231,  0.1161,  0.1091,  0.1021,  0.0951],\n",
      "         [ 0.1500,  0.2000,  0.2500,  0.3000,  0.3500],\n",
      "         [ 0.1161,  0.1091,  0.1021,  0.0951,  0.0882],\n",
      "         [ 0.2000,  0.2500,  0.3000,  0.3500,  0.4000],\n",
      "         [ 0.1091,  0.1021,  0.0951,  0.0882,  0.0812],\n",
      "         [ 0.2500,  0.3000,  0.3500,  0.4000,  0.4500],\n",
      "         [ 0.1021,  0.0951,  0.0882,  0.0812,  0.0742],\n",
      "         [ 0.3000,  0.3500,  0.4000,  0.4500,  0.5000],\n",
      "         [ 0.0951,  0.0882,  0.0812,  0.0742,  0.0672]],\n",
      "\n",
      "        [[ 0.3500,  0.4000,  0.4500,  0.5000,  0.5500],\n",
      "         [ 0.0882,  0.0812,  0.0742,  0.0672,  0.0602],\n",
      "         [ 0.4000,  0.4500,  0.5000,  0.5500,  0.6000],\n",
      "         [ 0.0812,  0.0742,  0.0672,  0.0602,  0.0532],\n",
      "         [ 0.4500,  0.5000,  0.5500,  0.6000,  0.6500],\n",
      "         [ 0.0742,  0.0672,  0.0602,  0.0532,  0.0463],\n",
      "         [ 0.5000,  0.5500,  0.6000,  0.6500,  0.7000],\n",
      "         [ 0.0672,  0.0602,  0.0532,  0.0463,  0.0393],\n",
      "         [ 0.5500,  0.6000,  0.6500,  0.7000,  0.7500],\n",
      "         [ 0.0602,  0.0532,  0.0463,  0.0393,  0.0323],\n",
      "         [ 0.6000,  0.6500,  0.7000,  0.7500,  0.8000],\n",
      "         [ 0.0532,  0.0463,  0.0393,  0.0323,  0.0253],\n",
      "         [ 0.6500,  0.7000,  0.7500,  0.8000,  0.8500],\n",
      "         [ 0.0463,  0.0393,  0.0323,  0.0253,  0.0183],\n",
      "         [ 0.7000,  0.7500,  0.8000,  0.8500,  0.9000]]], dtype=torch.float64, device='cuda:0')\n",
      "tensor([[[ 0.1091],\n",
      "         [ 0.2500],\n",
      "         [ 0.1021],\n",
      "         [ 0.3000],\n",
      "         [ 0.0951],\n",
      "         [ 0.3500],\n",
      "         [ 0.0882],\n",
      "         [ 0.4000],\n",
      "         [ 0.0812],\n",
      "         [ 0.4500],\n",
      "         [ 0.0742],\n",
      "         [ 0.5000],\n",
      "         [ 0.0672],\n",
      "         [ 0.5500],\n",
      "         [ 0.0602]],\n",
      "\n",
      "        [[ 0.6000],\n",
      "         [ 0.0532],\n",
      "         [ 0.6500],\n",
      "         [ 0.0463],\n",
      "         [ 0.7000],\n",
      "         [ 0.0393],\n",
      "         [ 0.7500],\n",
      "         [ 0.0323],\n",
      "         [ 0.8000],\n",
      "         [ 0.0253],\n",
      "         [ 0.8500],\n",
      "         [ 0.0183],\n",
      "         [ 0.9000],\n",
      "         [ 0.0113],\n",
      "         [ 0.9500]]], dtype=torch.float64, device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDNN_STATUS_EXECUTION_FAILED",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-16eebf7167e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/frcnn/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-3b0f98a19585>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (seq, batch, hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/frcnn/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/frcnn/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    190\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         )\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/frcnn/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/frcnn/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, weight, hx, batch_sizes)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         dropout_ts = cudnn.rnn.init_dropout_state(torch.uint8, torch.device('cuda'), dropout,\n\u001b[0;32m--> 275\u001b[0;31m                                                   train, dropout_seed, dropout_state)\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mweight_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.3/envs/frcnn/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_dropout_state\u001b[0;34m(ty, device, dropout, train, dropout_seed, dropout_state)\u001b[0m\n\u001b[1;32m     42\u001b[0m         dropout_state[dropout_desc_name] = Unserializable(\n\u001b[1;32m     43\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cudnn_init_dropout_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_seed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         )\n\u001b[1;32m     46\u001b[0m     \u001b[0mdropout_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdropout_desc_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDNN_STATUS_EXECUTION_FAILED"
     ]
    }
   ],
   "source": [
    "# training \n",
    "print(train_x)\n",
    "t0= time.time()\n",
    "for e in range(epochs):\n",
    "    if (e+1) % 100 == 0: \n",
    "        dt=time.time()-t0\n",
    "        t0=dt+t0\n",
    "        print('-'* 20 + ' Epoch {} - {:.2f}% - Time {:.2f}s '.format(e+1, (e+1)/epochs*100, dt) +'-'*20)\n",
    "    for i in np.arange(len(train_x)):\n",
    "        var_x = Variable(train_x[i])\n",
    "        var_y = Variable(train_y[i])\n",
    "        print(var_x)\n",
    "        print(var_y)\n",
    "        for name in models:\n",
    "            out = net[name](var_x)\n",
    "            loss = criterion(out, var_y)\n",
    "            optimizer[name].zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer[name].step()\n",
    "        if (e+1) % 100 == 0: \n",
    "            print('{}: Loss: {:.5f}'.format(name, loss.item()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in models:\n",
    "    net[name] = net[name].eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test={}\n",
    "test_x=Variable(train_x)\n",
    "for name in models: \n",
    "    test[name] = net[name](test_x)\n",
    "    loss = criterion(test[name], train_y)\n",
    "    print('{}: Loss: {:.5f}'.format(name, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name in models:\n",
    "    plt.plot( test[name].view(-1).data.cpu().numpy(), label=name)\n",
    "plt.plot(dataset, 'b', label='real')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
